# -*- coding: utf-8 -*-
"""Modelo Predictivo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H3uMJ_IA_N_dI97BhHnSvRgzz6Qbx2AP
"""

file_path = '/content/gdrive/My Drive/Analitica/Proyecto 2/new_data.csv'
import pandas as pd
from google.colab import drive
drive.mount('/content/gdrive')
data = pd.read_csv(file_path, index_col=0)

data.head()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.metrics import classification_report, confusion_matrix

# Assuming 'data' DataFrame is already prepared as in your previous code

# Define features (X) and target variable (y)
X = data.drop('y', axis=1)
y = data['y']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale numerical features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


# Build the neural network model
model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],))) # Increased neurons
model.add(BatchNormalization()) # Added Batch Normalization
model.add(Dropout(0.3)) #Increased Dropout rate
model.add(Dense(64, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.3))
model.add(Dense(32, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
optimizer = keras.optimizers.Adam(learning_rate=0.001) # Adjust learning rate if needed
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1,callbacks=[early_stopping])

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

# Make predictions

# Experiment with different thresholds
thresholds = [0.2,0.3, 0.4, 0.5, 0.6]  #Example thresholds
for threshold in thresholds:
  y_pred = (y_pred_prob > threshold).astype(int)
  print(f"Classification report with threshold {threshold}:")
  print(classification_report(y_test, y_pred))
  print("-" * 50)
  # Confusion Matrix
  print(confusion_matrix(y_test,y_pred))

# Classification Report
y_pred = (y_pred_prob > 0.2).astype(int)
print(classification_report(y_test, y_pred))

# ... (your existing code for data loading and preprocessing)

# Convert 'y_train' to integers (int32 or int64)
y_train = y_train.astype(int)

# Calculate class weights to address potential imbalance
# No changes needed here as the error will be fixed above
class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
class_weight_dict = dict(enumerate(class_weights))

# ... (rest of your code)

# Confusion Matrix
y_pred = (y_pred_prob > 0.2).astype(int)
print(confusion_matrix(y_test,y_pred))

keras.utils.plot_model(model, show_shapes=True, rankdir="LR")

# prompt: sacame el promedio de balance cuando el valor de y es 1

# Assuming 'data' DataFrame is already loaded and processed

# Filter the DataFrame for rows where 'y' is 1
subset = data[data['y'] == 1]

# Calculate the mean of the 'balance' column for the filtered data
average_balance = subset['balance'].mean()

print(f"The average balance when y is 1 is: {average_balance}")

# prompt: Ahora necesito que me generes los ingresos del banco teneindo en cuenta la matriz de cinducion y esta ecuacion ingresos= (precio(un 20% del ingreso segun su usuario true positive)-costo de contacto(2 euros))*(true positive/100)+(-costo de contacto*(False Positive/100))+(-precio)*(false Negative/100))

import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix

# ... (your existing code for data loading, model training, and prediction)

# Assuming y_test and y_pred are already defined
# Example values for demonstration
y_pred_prob = model.predict(X_test)  # Assuming you have y_pred_prob
y_pred = (y_pred_prob > 0.2).astype(int)


# Calculate confusion matrix elements
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# Define price and cost
price = 0.2 * average_balance # Example, replace with actual calculation based on user profile
cost_contact = 3

# Calculate income
income = ((price - cost_contact) * (tp / 100)) + (-cost_contact * (fp / 100)) + (-price * (fn / 100))

print(f"True Positive: {tp}")
print(f"False Positive: {fp}")
print(f"False Negative: {fn}")
print(f"True Negative: {tn}")

print(f"Income: {income}")