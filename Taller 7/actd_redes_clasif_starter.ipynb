{"cells":[{"cell_type":"markdown","metadata":{"id":"_Hq739EyGb3y"},"source":["## ACTD 2024 - 20"]},{"cell_type":"markdown","metadata":{"id":"fJkJsOuHGb30"},"source":["### Clases 13-14: redes neuronales para clasificación\n","\n","- Redes densas\n","- Redes para clasificación\n","- Procesamiento de datos continuos y categóricos\n","- Funciones de activación y pérdida"]},{"cell_type":"markdown","metadata":{"id":"OXCuT4WNIQRr"},"source":["Empecemos importando numpy, pandas, keras, tensorflow"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting tensorflow\n","  Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n","Collecting tensorflow-intel==2.17.0 (from tensorflow)\n","  Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n","Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n","Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n","Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n","Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n","Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n","Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n","Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n","Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: packaging in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (74.1.2)\n","Requirement already satisfied: six>=1.12.0 in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n","Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n","Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n","Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading grpcio-1.66.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n","Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n","Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n","Collecting numpy<2.0.0,>=1.26.0 (from tensorflow-intel==2.17.0->tensorflow)\n","  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n","Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow)\n","  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting rich (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n","  Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n","Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n","  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n","Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n","  Downloading optree-0.12.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n","Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n","  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n","  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n","Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n","  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\saral\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n","Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n","  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n","Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl (2.0 kB)\n","Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl (385.2 MB)\n","   ---------------------------------------- 0.0/385.2 MB ? eta -:--:--\n","    --------------------------------------- 8.9/385.2 MB 46.0 MB/s eta 0:00:09\n","   -- ------------------------------------- 19.4/385.2 MB 47.0 MB/s eta 0:00:08\n","   -- ------------------------------------- 28.0/385.2 MB 45.6 MB/s eta 0:00:08\n","   --- ------------------------------------ 38.0/385.2 MB 45.5 MB/s eta 0:00:08\n","   ----- ---------------------------------- 48.2/385.2 MB 46.5 MB/s eta 0:00:08\n","   ------ --------------------------------- 59.5/385.2 MB 46.8 MB/s eta 0:00:07\n","   ------- -------------------------------- 70.0/385.2 MB 47.5 MB/s eta 0:00:07\n","   -------- ------------------------------- 81.0/385.2 MB 47.4 MB/s eta 0:00:07\n","   --------- ------------------------------ 91.8/385.2 MB 48.0 MB/s eta 0:00:07\n","   ---------- ---------------------------- 101.4/385.2 MB 47.6 MB/s eta 0:00:06\n","   ----------- --------------------------- 112.5/385.2 MB 47.9 MB/s eta 0:00:06\n","   ------------ -------------------------- 121.6/385.2 MB 47.4 MB/s eta 0:00:06\n","   ------------- ------------------------- 129.2/385.2 MB 46.6 MB/s eta 0:00:06\n","   -------------- ------------------------ 139.7/385.2 MB 46.5 MB/s eta 0:00:06\n","   -------------- ------------------------ 146.5/385.2 MB 45.9 MB/s eta 0:00:06\n","   ---------------- ---------------------- 158.9/385.2 MB 46.3 MB/s eta 0:00:05\n","   ----------------- --------------------- 169.3/385.2 MB 46.4 MB/s eta 0:00:05\n","   ------------------ -------------------- 180.6/385.2 MB 46.7 MB/s eta 0:00:05\n","   ------------------- ------------------- 192.2/385.2 MB 47.0 MB/s eta 0:00:05\n","   -------------------- ------------------ 203.9/385.2 MB 47.6 MB/s eta 0:00:04\n","   --------------------- ----------------- 214.7/385.2 MB 47.5 MB/s eta 0:00:04\n","   ---------------------- ---------------- 226.0/385.2 MB 47.7 MB/s eta 0:00:04\n","   ----------------------- --------------- 234.6/385.2 MB 47.6 MB/s eta 0:00:04\n","   ------------------------ -------------- 245.6/385.2 MB 47.7 MB/s eta 0:00:03\n","   ------------------------- ------------- 255.9/385.2 MB 47.7 MB/s eta 0:00:03\n","   --------------------------- ----------- 267.4/385.2 MB 48.0 MB/s eta 0:00:03\n","   ---------------------------- ---------- 278.4/385.2 MB 48.2 MB/s eta 0:00:03\n","   ----------------------------- --------- 290.2/385.2 MB 48.7 MB/s eta 0:00:02\n","   ------------------------------ -------- 302.0/385.2 MB 49.0 MB/s eta 0:00:02\n","   ------------------------------- ------- 313.5/385.2 MB 49.2 MB/s eta 0:00:02\n","   -------------------------------- ------ 323.7/385.2 MB 48.9 MB/s eta 0:00:02\n","   --------------------------------- ----- 334.0/385.2 MB 49.0 MB/s eta 0:00:02\n","   ---------------------------------- ---- 343.1/385.2 MB 48.7 MB/s eta 0:00:01\n","   ----------------------------------- --- 352.8/385.2 MB 48.4 MB/s eta 0:00:01\n","   ------------------------------------ -- 362.3/385.2 MB 48.4 MB/s eta 0:00:01\n","   ------------------------------------- - 372.8/385.2 MB 48.4 MB/s eta 0:00:01\n","   --------------------------------------  382.7/385.2 MB 48.7 MB/s eta 0:00:01\n","   --------------------------------------  385.1/385.2 MB 48.3 MB/s eta 0:00:01\n","   --------------------------------------  385.1/385.2 MB 48.3 MB/s eta 0:00:01\n","   --------------------------------------  385.1/385.2 MB 48.3 MB/s eta 0:00:01\n","   --------------------------------------  385.1/385.2 MB 48.3 MB/s eta 0:00:01\n","   --------------------------------------  385.1/385.2 MB 48.3 MB/s eta 0:00:01\n","   --------------------------------------  385.1/385.2 MB 48.3 MB/s eta 0:00:01\n","   --------------------------------------- 385.2/385.2 MB 39.3 MB/s eta 0:00:00\n","Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n","Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n","Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n","Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Downloading grpcio-1.66.1-cp312-cp312-win_amd64.whl (4.3 MB)\n","   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n","   ---------------------------------------- 4.3/4.3 MB 42.7 MB/s eta 0:00:00\n","Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n","   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n","   ---------------------------------------- 3.0/3.0 MB 43.3 MB/s eta 0:00:00\n","Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n","   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n","   ---------------------------------------- 1.1/1.1 MB 58.9 MB/s eta 0:00:00\n","Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n","   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n","   ---------------- ----------------------- 11.0/26.4 MB 52.9 MB/s eta 0:00:01\n","   -------------------------------- ------- 21.2/26.4 MB 49.7 MB/s eta 0:00:01\n","   ---------------------------------------  26.2/26.4 MB 47.4 MB/s eta 0:00:01\n","   ---------------------------------------- 26.4/26.4 MB 34.9 MB/s eta 0:00:00\n","Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n","Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n","   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n","   ----------------------------- ---------- 11.3/15.5 MB 54.2 MB/s eta 0:00:01\n","   ---------------------------------------- 15.5/15.5 MB 44.5 MB/s eta 0:00:00\n","Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n","Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n","Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n","   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n","   ---------------------------------------- 5.5/5.5 MB 41.9 MB/s eta 0:00:00\n","Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n","Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n","Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n","Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n","Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n","Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Downloading optree-0.12.1-cp312-cp312-win_amd64.whl (267 kB)\n","Downloading rich-13.8.1-py3-none-any.whl (241 kB)\n","Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n","Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow-intel, tensorflow\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.1.1\n","    Uninstalling numpy-2.1.1:\n","      Successfully uninstalled numpy-2.1.1\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\saral\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\~umpy.libs'.\n","  You can safely remove it manually.\n","  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\saral\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\~umpy'.\n","  You can safely remove it manually.\n","ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\saral\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\com_github_grpc_grpc\\\\src\\\\core\\\\ext\\\\filters\\\\client_channel\\\\lb_policy\\\\grpclb\\\\client_load_reporting_filter.h'\n","HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n","\n"]}],"source":["!pip install tensorflow\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"XvZd5CxTGdcd"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import keras"]},{"cell_type":"markdown","metadata":{"id":"QbWocciXIZjU"},"source":["Carguemos el archivo auto-mpg.data (disponible en Bloque Neón) usando pandas. Note que debemos incluir los nombres de las columnas, además de indicar los caracteres para separación, nas y comentarios."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SrWIjZxQG-Pm"},"outputs":[],"source":["df = pd.read_csv('heart.csv')"]},{"cell_type":"markdown","metadata":{"id":"It4_BrEgI6_w"},"source":["Exploremos las primeras filas del dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjBQLhr3INGC"},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"Sf3tQ4SdKQy7"},"source":["Descripción de las variables:\n","\n","https://archive.ics.uci.edu/dataset/45/heart+disease\n"]},{"cell_type":"markdown","metadata":{"id":"GRDlL9vAJAz1"},"source":["Exploremos el tamaño del df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PeHyTPnEJC8f"},"outputs":[],"source":["df.shape"]},{"cell_type":"markdown","metadata":{"id":"dONjz931JFhG"},"source":["Identificamos NAs en los datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47pvp0jtJFKt"},"outputs":[],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{"id":"Ebb_FtLdmEgT"},"source":["Definimos listas para las variables categóricas enteras, categóricas string y numéricas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6HARyge_bKP"},"outputs":[],"source":["cat_int_feats = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'ca']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"onEA7I5N_ek0"},"outputs":[],"source":["cat_str_feats = ['thal']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YxwNz_7y_hrv"},"outputs":[],"source":["num_feats = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope']"]},{"cell_type":"markdown","metadata":{"id":"hL-Zip0OmNru"},"source":["Agregamos las listas de categorías"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DBzj4Qxr_kR1"},"outputs":[],"source":["feats_ordered = cat_int_feats+cat_str_feats+num_feats"]},{"cell_type":"markdown","metadata":{"id":"P_Mlzsv9mRH3"},"source":["Reordenamos el dataframe de acuerdo con el tipo de variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yH8Xsu1a_ohM"},"outputs":[],"source":["df = df[feats_ordered+['target']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QY-c3kZD_paR"},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"8Ls8L1hRMQh4"},"source":["Separamos los datos en entrenamiento, validación y prueba"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dADsWjtMTcS"},"outputs":[],"source":["train = df.sample(frac=0.8, random_state=100)\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZOQNUy2jSwH"},"outputs":[],"source":["train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TC9xJuiKMenc"},"outputs":[],"source":["test = df.drop(train.index)\n","test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z3Bmb1Npj_zu"},"outputs":[],"source":["val = train.sample(frac=0.2, random_state=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfSRCJElkP4U"},"outputs":[],"source":["val.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Ptvi_pBkImU"},"outputs":[],"source":["train = train.drop(val.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-H2PITXhMmcz"},"outputs":[],"source":["print(train.shape)\n","print(val.shape)\n","print(test.shape)"]},{"cell_type":"markdown","metadata":{"id":"t58x12kjNrK7"},"source":["Calculamos estadísticas de cada variable numérica"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ycw_T_PnNtmr"},"outputs":[],"source":["train.describe()"]},{"cell_type":"markdown","metadata":{"id":"O0kwTMsxPEC-"},"source":["Función para convertir de dataframe (pandas) a dataset (tensorflow), separando características y etiquetas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mMPXHVzty85"},"outputs":[],"source":["def dataframe_to_dataset(dataframe):\n","    dataframe = dataframe.copy()\n","    labels = dataframe.pop(\"target\")\n","    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n","    ds = ds.shuffle(buffer_size=len(dataframe))\n","    return ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajCnnkOvt2yZ"},"outputs":[],"source":["train_ds = dataframe_to_dataset(train)\n","val_ds = dataframe_to_dataset(val)\n","test_ds = dataframe_to_dataset(test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWOTIj3MuFHT"},"outputs":[],"source":["type(train_ds)"]},{"cell_type":"markdown","metadata":{"id":"OzN2TbxKmv5J"},"source":["Ejemplo de cómo queda el tf.dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Kis1GC_uP94"},"outputs":[],"source":["for x, y in train_ds.take(1):\n","    print(\"Input:\", x)\n","    print(\"Target:\", y)"]},{"cell_type":"markdown","metadata":{"id":"fqfXQMammzE5"},"source":["Separamos los datos de entrenamiento, validación y prueba en lotes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYSJR321ucz4"},"outputs":[],"source":["batch_size = 32\n","train_ds = train_ds.batch(batch_size)\n","test_ds = test_ds.batch(batch_size)\n","val_ds = val_ds.batch(batch_size)"]},{"cell_type":"markdown","metadata":{"id":"gekvkTr8vem7"},"source":["Función para codificar variables numéricas (Keras docs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHL-Xz2vvcPz"},"outputs":[],"source":["def encode_numerical_feature(feature, name, dataset):\n","    # Crea capa de normalización para este feature\n","    normalizer = keras.layers.Normalization()\n","\n","    # Prepara el dataset para considerar únicamente la feature de interés (name)\n","    feature_ds = dataset.map(lambda x, y: x[name]) # selecciona variable\n","    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1)) # deja el tensor de una dimensión\n","\n","    # Aprende las estadísticas de los datos (media, varianza)\n","    normalizer.adapt(feature_ds)\n","\n","    # Aplica la normalización a la variable\n","    encoded_feature = normalizer(feature)\n","    return encoded_feature"]},{"cell_type":"markdown","metadata":{"id":"-2egk2GMvrYW"},"source":["Función para codificar variables categóricas (Keras docs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6XFsdP3vxI4"},"outputs":[],"source":["def encode_categorical_feature(feature, name, dataset, is_string):\n","    lookup_class = keras.layers.StringLookup if is_string else keras.layers.IntegerLookup\n","    # Crea una capa Lookup para retornas variables 0/1 (dummies)\n","    # lookup: busca el valor correspondiente de la variable categórica\n","    lookup = lookup_class(output_mode=\"binary\")\n","\n","    # Prepara el dataset para considerar únicamente la feature de interés (name)\n","    feature_ds = dataset.map(lambda x, y: x[name]) # selecciona variable\n","    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1)) # deja el tensor de una dimensión\n","\n","    # Aprende el conjunto de posibles valores que toma la variable categórica y asigna enteros\n","    lookup.adapt(feature_ds)\n","\n","    # Aplica la conversión de categorías a enteros\n","    encoded_feature = lookup(feature)\n","    return encoded_feature"]},{"cell_type":"markdown","metadata":{"id":"pxFez9T6ib3x"},"source":["Creamos una lista de inputs para el modelo, de acuerdo con cada tipo de variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qe4JwN9Jv4g8"},"outputs":[],"source":["inputs = []\n","for i in cat_int_feats:\n","  inputs.append(keras.Input(shape=(1,), name=i, dtype=\"int64\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8My9fdD9wdpO"},"outputs":[],"source":["for i in cat_str_feats:\n","  inputs.append(keras.Input(shape=(1,), name=i, dtype=\"string\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6smPNUmwwpC0"},"outputs":[],"source":["for i in num_feats:\n","  inputs.append(keras.Input(shape=(1,), name=i))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iViUbLxzwyqK"},"outputs":[],"source":["for i in inputs:\n","   print(i)"]},{"cell_type":"markdown","metadata":{"id":"QNRJIbFhihq1"},"source":["Creamos una lista de variables codificadas/normalizadas de acuerdo con su tipo, empleando las funciones de codificación/normalización"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QZFZk7n1w18S"},"outputs":[],"source":["feats_encoded=[]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNsjUGDyxEFU"},"outputs":[],"source":["for i,feat in enumerate(cat_int_feats):\n","  feats_encoded.append(\n","      encode_categorical_feature(inputs[i], feat, train_ds, False)\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NoGZIhI5yNF8"},"outputs":[],"source":["len_feats = len(feats_encoded)\n","len_feats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4FB7nNZyMla"},"outputs":[],"source":["for i,feat in enumerate(cat_str_feats):\n","  feats_encoded.append(\n","      encode_categorical_feature(inputs[len_feats+i], feat, train_ds, True)\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQx1yyshykyC"},"outputs":[],"source":["len_feats = len(feats_encoded)\n","len_feats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uW6cMxRmyoPq"},"outputs":[],"source":["for i,feat in enumerate(num_feats):\n","  feats_encoded.append(\n","      encode_numerical_feature(inputs[len_feats+i], feat, train_ds)\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8787d5HzklR"},"outputs":[],"source":["for i in feats_encoded:\n","  print(i)"]},{"cell_type":"markdown","metadata":{"id":"O7Wkmq4_iu7C"},"source":["Creamos una capa concatenando todas las variables codificadas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MnCXNQmVzvFo"},"outputs":[],"source":["all_feats = keras.layers.concatenate(feats_encoded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaQ-LGQ-z1dZ"},"outputs":[],"source":["type(all_feats)"]},{"cell_type":"markdown","metadata":{"id":"jJDu5_h4i5K2"},"source":["Agregamos una capa densa con 32 neuronas y función de activación relu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fQNOhhC0UKq"},"outputs":[],"source":["model_layers = keras.layers.Dense(32, activation='relu')(all_feats)"]},{"cell_type":"markdown","metadata":{"id":"VpOkMLORjBus"},"source":["Agregamos la capa de salida con 1 neurona (probabilidad de sufrir la enfermedad cardiada) y función de activación sigmoide"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-hJ3U5gg0cRa"},"outputs":[],"source":["model_layers = keras.layers.Dense(1, activation='sigmoid')(model_layers)"]},{"cell_type":"markdown","metadata":{"id":"UE2Q7SqsjOZX"},"source":["Creamos el modelo con las capas ya creadas y las variables de entrada"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hcQSv0j2z58b"},"outputs":[],"source":["model = keras.Model(inputs, model_layers)"]},{"cell_type":"markdown","metadata":{"id":"ZNagIagJjXNG"},"source":["Compilamos el modelo, definiendo optimizador, función de pérdida y métricas adicionales a capturar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mkx1iu9i0qZR"},"outputs":[],"source":["model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLhp4Tdf1jPM"},"outputs":[],"source":["keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"]},{"cell_type":"markdown","metadata":{"id":"boQih7bljscZ"},"source":["Aseguramos que Keras use TensorFlow como backend, para asegurar que el modelo pueda usar strings como entradas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_mKv-Bn6h4H"},"outputs":[],"source":["import os\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""]},{"cell_type":"markdown","metadata":{"id":"z-2-ELq4jtdb"},"source":["Entrenamos el modelo con los datos en el formato tf.Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DebRVUwi04dx"},"outputs":[],"source":["model.fit(train_ds, epochs=50, validation_data=val_ds)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
